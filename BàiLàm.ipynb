{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279b14ee",
   "metadata": {},
   "source": [
    "# Bài Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e299ac",
   "metadata": {},
   "source": [
    "Bài 1: Viết một chương trình nhập vào một file văn bản bằng tiếng anh và thống kê số lần xuất hiện của các từ trong văn bản đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d22c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "def word_frequency(file_path):\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    @return dictionary contains word frequency\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = word_tokenize(line.strip().lower())\n",
    "        data.append(sent)\n",
    "\n",
    "    word_freq = Counter(chain(*data))\n",
    "    return dict(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82f69f",
   "metadata": {},
   "source": [
    "Thử hàm với file toy_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63fb239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 2,\n",
       " 'do': 1,\n",
       " \"n't\": 1,\n",
       " 'want': 1,\n",
       " 'to': 3,\n",
       " 'go': 2,\n",
       " 'school': 1,\n",
       " 'have': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency(\"toy_dataset.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c0b31",
   "metadata": {},
   "source": [
    "Bài 2: Cho dạng ngày tháng: YYYY-mm-dd. Viết biểu thức chính quy kiểm tra một dãy ký tự có phải là dạng ngày tháng năm đã cho ở trên hay không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e87fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def check_form(date):\n",
    "    \"\"\"\n",
    "    @param date (str): string to check\n",
    "    @return boolean: True if date is in the correct form or False if not\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"^\\d{4}-(02-(0[1-9]|[12][0-9])|(0[469]|11)-(0[1-9]|[12][0-9]|30)|(0[13578]|1[02])-(0[1-9]|[12][0-9]|3[01]))$\")\n",
    "    if pattern.search(date):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec3be3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_form(\"2020-04-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7d8f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_form(\"2020-04-30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff930d3",
   "metadata": {},
   "source": [
    "Bài 3: \n",
    "3.1 Đọc và phân chia dữ liệu thành 3 tập train.txt, dev.txt, test.txt với tỉ lệ 7:1:2, nhãn 1 và 0 cân bằng trên cả 3 hệ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193287e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc file dataset\n",
    "data = []\n",
    "label = []\n",
    "for line in open(\"dataset.txt\"):\n",
    "    x = line.strip().lower()\n",
    "    label.append(int(x[-1]))\n",
    "    data.append(x[:-1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb633a9b",
   "metadata": {},
   "source": [
    "Chia dữ liệu thành 2 phần train và test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0a8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(data, label, test_size = 0.2, random_state = 1, stratify=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc244d",
   "metadata": {},
   "source": [
    "Rồi lại chia tập train thành 2 phần là train và develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91bc137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_dev, y_train, y_dev = train_test_split(X_train, Y_train, test_size = 0.125, random_state = 1, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78c088",
   "metadata": {},
   "source": [
    "Lưu dữ liệu vào file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a62615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "f = open('train.txt', 'w')\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    f.write(x_train[i] + \"\\t\" + str(y_train[i]) + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "# dev\n",
    "f = open('dev.txt', 'w')\n",
    "\n",
    "for i in range(len(x_dev)):\n",
    "    f.write(x_dev[i] + \"\\t\" + str(y_dev[i]) + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "# test\n",
    "f = open('test.txt', 'w')\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    f.write(x_test[i] + \"\\t\" + str(y_test[i]) + \"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c4e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X_train = [word_tokenize(seq) for seq in x_train]\n",
    "x_dev = [word_tokenize(seq) for seq in x_dev]\n",
    "x_test = [word_tokenize(seq) for seq in x_test]\n",
    "y_dev = torch.LongTensor(y_dev)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad9271",
   "metadata": {},
   "source": [
    " 3.2 Xây dựng một model từ tập train và dev rồi sau đó eval dựa trên tập test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf86acfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types: 1651, number of word types w/ frequency >= 5: 273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import RNNModel, RNNClassifierModel\n",
    "from vocab import Vocab\n",
    "\n",
    "# xây dựng vocab dựa vào tập train\n",
    "vocab = Vocab.from_corpus(X_train, size = 300, freq_cutoff=5)\n",
    "\n",
    "# xây dựng mạng RNN sử dụng LSTM\n",
    "rnn = RNNModel(len(vocab),rnn_cell_class=nn.LSTM, bidirectional=True, embed_dim=40, hidden_dim=60)\n",
    "\n",
    "# Xây dựng model\n",
    "RNN = RNNClassifierModel(rnn, output_dim = 2, classifier_activation = nn.Tanh(), vocab = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a175aa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 15.19, epoch: 0\n",
      "Loss: 15.06, epoch: 2\n",
      "Save model with dev_f1_score = 0.60\n",
      "save model parameters to [model.bin]\n",
      "Loss: 14.94, epoch: 4\n",
      "Loss: 14.80, epoch: 6\n",
      "Save model with dev_f1_score = 0.61\n",
      "save model parameters to [model.bin]\n",
      "Loss: 14.63, epoch: 8\n",
      "Loss: 14.40, epoch: 10\n",
      "Loss: 14.08, epoch: 12\n",
      "Loss: 13.62, epoch: 14\n",
      "Save model with dev_f1_score = 0.63\n",
      "save model parameters to [model.bin]\n",
      "Loss: 13.05, epoch: 16\n",
      "Loss: 12.19, epoch: 18\n",
      "Loss: 11.31, epoch: 20\n",
      "Loss: 10.56, epoch: 22\n",
      "Loss: 9.96, epoch: 24\n",
      "Save model with dev_f1_score = 0.66\n",
      "save model parameters to [model.bin]\n",
      "Loss: 9.23, epoch: 26\n",
      "Loss: 8.70, epoch: 28\n",
      "Save model with dev_f1_score = 0.67\n",
      "save model parameters to [model.bin]\n",
      "Loss: 8.12, epoch: 30\n",
      "Save model with dev_f1_score = 0.68\n",
      "save model parameters to [model.bin]\n",
      "Loss: 7.62, epoch: 32\n",
      "Loss: 7.30, epoch: 34\n",
      "Save model with dev_f1_score = 0.69\n",
      "save model parameters to [model.bin]\n",
      "Loss: 6.68, epoch: 36\n",
      "Loss: 6.33, epoch: 38\n",
      "Loss: 5.87, epoch: 40\n",
      "Loss: 5.92, epoch: 42\n",
      "Loss: 5.20, epoch: 44\n",
      "Load previously best model and decay learning rate to 0.000050\n",
      "Loss: 6.83, epoch: 46\n",
      "Loss: 6.70, epoch: 48\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def length(data):\n",
    "    return torch.LongTensor([len(seq) for seq in data])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data,label = zip(*batch)\n",
    "    y = torch.LongTensor(label)\n",
    "    x = [word_tokenize(seq) for seq in data]\n",
    "    return x, y\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "lr_decay = 0.5\n",
    "epochs = 50\n",
    "model_save_path = \"model.bin\"\n",
    "patience = 0\n",
    "\n",
    "data = list(zip(x_train, y_train))\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = torch.optim.Adam(RNN.parameters(), lr=learning_rate)\n",
    "lossfunction = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    RNN.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = RNN(x, length(x)) \n",
    "        \n",
    "        loss = lossfunction(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss\n",
    "    \n",
    "    # Early stop and decay lr\n",
    "    if epoch %2 ==0:\n",
    "        print(\"Loss: {:.2f}, epoch: {}\".format(total_loss, epoch))\n",
    "        RNN.eval()\n",
    "        with torch.no_grad():\n",
    "            y_dev_pre = RNN.predict(x_dev, length(x_dev))\n",
    "            score = f1_score(y_dev, y_dev_pre, average = \"macro\")\n",
    "        if epoch == 0:\n",
    "            best_score = score\n",
    "        if score> best_score:\n",
    "            patience = 0\n",
    "            best_score = score\n",
    "            print(\"Save model with dev_f1_score = {:.2f}\".format(best_score))\n",
    "            RNN.save(model_save_path)\n",
    "            \n",
    "        else:\n",
    "            patience += 1\n",
    "        if patience == 5:\n",
    "            # decay lr, and restore from previously best checkpoint\n",
    "            lr = optimizer.param_groups[0]['lr'] * lr_decay\n",
    "            print('Load previously best model and decay learning rate to %f' % lr)\n",
    "            RNN = RNNClassifierModel.load(model_save_path)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(RNN.parameters(), lr=lr)\n",
    "            \n",
    "            # reset patience\n",
    "            patience = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e47a8d",
   "metadata": {},
   "source": [
    "Đánh giá model dựa vào tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5640d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60       100\n",
      "           1       0.60      0.61      0.61       100\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.61      0.60      0.60       200\n",
      "weighted avg       0.61      0.60      0.60       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RNN = RNNClassifierModel.load(model_save_path)\n",
    "y_pred = RNN.predict(x_test, length(x_test))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93487a",
   "metadata": {},
   "source": [
    "Ta sẽ đánh giá model trên dựa vào giá trị của \"Macro F1 Score\". Kết quả cũng có thể tạm chấp nhận được vì model mà ta xây dựng khá là đơn giản và tập dữ liệu training chỉ có 700 sample - 1 tập dữ liệu rất bé.\n",
    "Để cải thiện bài toán, ta cần phải:\n",
    "- Thu thập nhiều dữ liệu training hơn\n",
    "- Sau khi có đủ lượng dữ liệu training cần thiết, sử dụng Deep Bidirectional LSTM thay vì chỉ 1 layer Bidirectional LSTM như bài làm trên. Hoặc có thể sử dụng cách tiếp cận khác: Fine-tuning Bert Pretrained để xem kết quả có cả thiện hơn so với các cách tiếp cận trước đó hay không\n",
    "- Bài làm trên sử dụng \"last_hidden_state\" để predict label, ta cũng có thể có hướng tiếp cận khác: Thay vì sử dụng \"last_hidden_state\", chúng ta cộng tổng và lấy trung bình của các \"hidden_state\"\n",
    "- HyperParameter Search cũng là một trong những cách để cải thiện kết quả\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43934603",
   "metadata": {},
   "source": [
    "3.3 Xây dựng một chương trình tương tác cho phép nhập một câu từ dòng lệnh và dự đoán ra nhãn 1 hay 0 cho câu nhập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87e899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 1-positive, 0-negative\n",
      "Điền câu để kiểm tra:The food is good\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from model import RNNClassifierModel\n",
    "import torch\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def deploy():\n",
    "    RNN = RNNClassifierModel.load(\"model.bin\")\n",
    "    print(\"Sentiment Analysis: 1-positive, 0-negative\")\n",
    "    seq = input(\"Điền câu để kiểm tra:\")\n",
    "    x = [word_tokenize(seq)]\n",
    "    l = torch.LongTensor([len(x[0])])\n",
    "    print(RNN.predict(x,l).item())\n",
    "deploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
